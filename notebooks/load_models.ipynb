{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "          Identity-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
      "           Conv2d-13          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
      "             ReLU-15          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-16          [-1, 256, 32, 32]               0\n",
      "           Conv2d-17           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 32, 32]             128\n",
      "             ReLU-19           [-1, 64, 32, 32]               0\n",
      "           Conv2d-20           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 32, 32]             128\n",
      "             ReLU-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "             ReLU-25          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-26          [-1, 256, 32, 32]               0\n",
      "           Conv2d-27           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 32, 32]             128\n",
      "             ReLU-29           [-1, 64, 32, 32]               0\n",
      "           Conv2d-30           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 32, 32]             128\n",
      "             ReLU-32           [-1, 64, 32, 32]               0\n",
      "           Conv2d-33          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 32, 32]             512\n",
      "             ReLU-35          [-1, 256, 32, 32]               0\n",
      "       Bottleneck-36          [-1, 256, 32, 32]               0\n",
      "           Conv2d-37          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "             ReLU-39          [-1, 128, 32, 32]               0\n",
      "           Conv2d-40          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 16, 16]             256\n",
      "             ReLU-42          [-1, 128, 16, 16]               0\n",
      "           Conv2d-43          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-45          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-47          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "           Conv2d-55          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-57          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-58          [-1, 512, 16, 16]               0\n",
      "           Conv2d-59          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 16, 16]             256\n",
      "             ReLU-61          [-1, 128, 16, 16]               0\n",
      "           Conv2d-62          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 16, 16]             256\n",
      "             ReLU-64          [-1, 128, 16, 16]               0\n",
      "           Conv2d-65          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-67          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-68          [-1, 512, 16, 16]               0\n",
      "           Conv2d-69          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 16, 16]             256\n",
      "             ReLU-71          [-1, 128, 16, 16]               0\n",
      "           Conv2d-72          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
      "             ReLU-74          [-1, 128, 16, 16]               0\n",
      "           Conv2d-75          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-77          [-1, 512, 16, 16]               0\n",
      "       Bottleneck-78          [-1, 512, 16, 16]               0\n",
      "           Conv2d-79          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 16, 16]             512\n",
      "             ReLU-81          [-1, 256, 16, 16]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "           Conv2d-85           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-87           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-89           [-1, 1024, 8, 8]               0\n",
      "       Bottleneck-90           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "             ReLU-99           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-100           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-101            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 8, 8]             512\n",
      "            ReLU-103            [-1, 256, 8, 8]               0\n",
      "          Conv2d-104            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 8, 8]             512\n",
      "            ReLU-106            [-1, 256, 8, 8]               0\n",
      "          Conv2d-107           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-109           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-110           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-111            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 8, 8]             512\n",
      "            ReLU-113            [-1, 256, 8, 8]               0\n",
      "          Conv2d-114            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 8, 8]             512\n",
      "            ReLU-116            [-1, 256, 8, 8]               0\n",
      "          Conv2d-117           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-119           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-120           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-121            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 8, 8]             512\n",
      "            ReLU-123            [-1, 256, 8, 8]               0\n",
      "          Conv2d-124            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 8, 8]             512\n",
      "            ReLU-126            [-1, 256, 8, 8]               0\n",
      "          Conv2d-127           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-129           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-130           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-131            [-1, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 8, 8]             512\n",
      "            ReLU-133            [-1, 256, 8, 8]               0\n",
      "          Conv2d-134            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 8, 8]             512\n",
      "            ReLU-136            [-1, 256, 8, 8]               0\n",
      "          Conv2d-137           [-1, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-139           [-1, 1024, 8, 8]               0\n",
      "      Bottleneck-140           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-141            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-143            [-1, 512, 8, 8]               0\n",
      "          Conv2d-144            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-146            [-1, 512, 4, 4]               0\n",
      "          Conv2d-147           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-149           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-151           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-152           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-153            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-155            [-1, 512, 4, 4]               0\n",
      "          Conv2d-156            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-158            [-1, 512, 4, 4]               0\n",
      "          Conv2d-159           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-161           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-162           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-163            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-165            [-1, 512, 4, 4]               0\n",
      "          Conv2d-166            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-168            [-1, 512, 4, 4]               0\n",
      "          Conv2d-169           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 4, 4]           4,096\n",
      "            ReLU-171           [-1, 2048, 4, 4]               0\n",
      "      Bottleneck-172           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 23,508,548\n",
      "Trainable params: 23,508,548\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 89.08\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 178.80\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import torchvision.transforms as trn\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "device = \"cuda\" \n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model,input_size = (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"../models/resnet50_2.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = \"../data/raw/train\"\n",
    "\n",
    "# from competition page\n",
    "transform = trn.Compose([\n",
    "        trn.Resize((64, 64)),\n",
    "        #trn.ToTensor(),\n",
    "        trn.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2, 1, 1, 2, 0, 1, 1, 1, 1, 3, 2, 3, 0, 1, 1, 0, 0, 1, 0, 1, 3, 1, 2, 1, 2, 2, 1, 0, 2, 1, 0, 0, 0, 1, 3, 0, 1, 0, 1, 1, 0, 2, 1, 1, 3, 0, 2, 2, 3, 1, 3, 2, 3, 1, 0, 3, 0, 2, 2, 3, 2, 0, 1, 1, 1, 2, 2, 2, 0, 0, 2, 2, 2, 3, 1, 0, 3, 3, 3, 1, 0, 1, 3, 0, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 0, 0, 3, 1, 3, 0, 2, 0, 1, 2, 1, 1, 3, 3, 1, 2, 3, 2, 3, 1, 2, 2, 1, 1, 3, 1, 2, 2, 0, 2, 1, 0, 1, 3, 1, 2, 2, 0, 3, 0, 2, 1, 2, 2, 1, 2, 3, 0, 2, 1, 3, 1, 0, 3] tensor([1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 3, 3, 1, 1, 2, 3, 1, 1, 1, 1, 3, 1, 1, 1,\n",
      "        3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 3, 1, 0, 1, 1, 1, 2, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy: 30.67%\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# sort like in vscode\n",
    "all_paths = list(Path(IMAGES_PATH).glob(\"*\"))\n",
    "all_paths = sorted(list(Path(IMAGES_PATH).glob(\"*\")),key=lambda x: int(x.stem.split(\"_\")[0]))\n",
    "\n",
    "\n",
    "\n",
    "for image in all_paths[:150]:\n",
    "    raw_image = torchvision.io.decode_image(image).float()\n",
    "    images.append(raw_image)\n",
    "    labels.append(int(image.stem.split(\"_\")[1]))\n",
    "\n",
    "batch = torch.stack(images)\n",
    "batch = transform(batch) # ??? transform or not? results are almost the same\n",
    "output = model(batch.to(device))\n",
    "\n",
    "predicted_classes = torch.argmax(output,dim=1)\n",
    "\n",
    "print(labels,predicted_classes)\n",
    "\n",
    "accuracy = (torch.tensor(labels, device=device) == predicted_classes).float().mean().item()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
